{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12-PyTorch-MobileNet.ipynb","provenance":[],"authorship_tag":"ABX9TyO9tlIf4CnMYO2IOrjpomZi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MUsIPvXx1cpE"},"source":["# Lightweight networks and MobileNet\n","\n","We have seen that complex networks require significant computational resources, such as GPU, for training, and also for fast inference. However, it turns out that a model with significantly smaller number of parameters in most cases can still be trained to perform reasonably well. In other words, increase in the model complexity typically results in small (non-proportional) increase in the model performance.\n","\n","We have observed this in the beginning of the module when training MNIST digit classification. The accuracy of simple dense model was not significantly worse than that of a powerful CNN. Increasing the number of CNN layers and/or number of neurons in the classifier allowed us to gain a few percents of accuracy at most.\n","\n","This leads us to the idea that we can experiment with Lightweight network architectures in order to train faster models. This is especially important if we want to be able to execute our models on mobile devices.\n","\n","This module will rely on the Cats and Dogs dataset that we have downloaded in the previous unit. First we will make sure that the dataset is available."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aslznL-11WYD","executionInfo":{"status":"ok","timestamp":1632739145346,"user_tz":-330,"elapsed":553,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}},"outputId":"7c800e17-e5ad-4f80-fba9-e3e39caa8db6"},"source":["!wget https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-27 10:39:06--  https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6371 (6.2K) [text/plain]\n","Saving to: ‘pytorchcv.py’\n","\n","\rpytorchcv.py          0%[                    ]       0  --.-KB/s               \rpytorchcv.py        100%[===================>]   6.22K  --.-KB/s    in 0s      \n","\n","2021-09-27 10:39:06 (52.6 MB/s) - ‘pytorchcv.py’ saved [6371/6371]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dECnvGBI1mtt","executionInfo":{"status":"ok","timestamp":1632739171478,"user_tz":-330,"elapsed":4388,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}},"outputId":"528f631f-2cb9-448e-8449-e5fb5a895449"},"source":["!pip install torchinfo"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.5.3\n"]}]},{"cell_type":"code","metadata":{"id":"gpXm3Btl1c_W","executionInfo":{"status":"ok","timestamp":1632739519276,"user_tz":-330,"elapsed":370,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","from torchinfo import summary\n","import os\n","\n","from pytorchcv import train, display_dataset, train_long, load_cats_dogs_dataset, validate, common_transform"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yY7Lzf8d1kce","executionInfo":{"status":"ok","timestamp":1632739204556,"user_tz":-330,"elapsed":21522,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}},"outputId":"fc4f60eb-ee58-42d1-fe24-3c65f3f7e756"},"source":["if not os.path.exists('data/kagglecatsanddogs_3367a.zip'):\n","    !wget -P data -q https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","\n","dataset, train_loader, test_loader = load_cats_dogs_dataset()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Corrupt image: data/PetImages/Cat/666.jpg\n","Corrupt image: data/PetImages/Dog/11702.jpg\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n","  warnings.warn(str(msg))\n"]}]},{"cell_type":"markdown","metadata":{"id":"fE3qx0A_1wk0"},"source":["## MobileNet\n","\n","In the previous unit, we have seen **ResNet** architecture for image classification. More lightweight analog of ResNet is **MobileNet**, which uses so-called *Inverted Residual Blocks*. Let's load pre-trained mobilenet and see how it works:\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdQot3Ir1sdK","executionInfo":{"status":"ok","timestamp":1632739523469,"user_tz":-330,"elapsed":384,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}},"outputId":"8d1b022c-585d-44fc-f855-41482851e71f"},"source":["model = models.mobilenet_v2()\n","model.eval()\n","print(model)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2(\n","  (features): Sequential(\n","    (0): ConvBNActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): ConvBNActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=1000, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KaUDBxL13go","executionInfo":{"status":"ok","timestamp":1632739536990,"user_tz":-330,"elapsed":1023,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}},"outputId":"ee595da2-33ec-4e96-9b76-62f427edc642"},"source":["sample_image = dataset[0][0].unsqueeze(0)\n","res = model(sample_image)\n","print(res[0].argmax())"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(536)\n"]}]},{"cell_type":"markdown","metadata":{"id":"VZqCX4dn3Fbe"},"source":["\n","## Using MobileNet for transfer learning\n","\n","Now let's perform the same transfer learning process as in previous unit, but using MobileNet. First of all, let's freeze all parameters of the model:"]},{"cell_type":"code","metadata":{"id":"1_v_WAX33Cn_","executionInfo":{"status":"ok","timestamp":1632739554263,"user_tz":-330,"elapsed":421,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}}},"source":["for x in model.parameters():\n","    x.requires_grad = False"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93ntlw9j3Jov"},"source":["Then, replace the final classifier. We also transfer the model to our default training device (GPU or CPU):"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfLKub5D3G_K","executionInfo":{"status":"ok","timestamp":1632739571066,"user_tz":-330,"elapsed":17,"user":{"displayName":"5017 Antony Prince J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ1EpzxQ0Pzucjqzck4vdLlLNjAmgR8aruHqvYpCA=s64","userId":"15960023355741151365"}},"outputId":"ef0a066d-dddf-499d-c302-4e3c412afb6a"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.classifier = nn.Linear(1280,2)\n","model = model.to(device)\n","summary(model,input_size=(1,3,244,244))"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["===============================================================================================\n","Layer (type:depth-idx)                        Output Shape              Param #\n","===============================================================================================\n","MobileNetV2                                   --                        --\n","├─Sequential: 1-1                             [1, 1280, 8, 8]           --\n","│    └─ConvBNActivation: 2-1                  [1, 32, 122, 122]         --\n","│    │    └─Conv2d: 3-1                       [1, 32, 122, 122]         (864)\n","│    │    └─BatchNorm2d: 3-2                  [1, 32, 122, 122]         (64)\n","│    │    └─ReLU6: 3-3                        [1, 32, 122, 122]         --\n","│    └─InvertedResidual: 2-2                  [1, 16, 122, 122]         --\n","│    │    └─Sequential: 3-4                   [1, 16, 122, 122]         (896)\n","│    └─InvertedResidual: 2-3                  [1, 24, 61, 61]           --\n","│    │    └─Sequential: 3-5                   [1, 24, 61, 61]           (5,136)\n","│    └─InvertedResidual: 2-4                  [1, 24, 61, 61]           --\n","│    │    └─Sequential: 3-6                   [1, 24, 61, 61]           (8,832)\n","│    └─InvertedResidual: 2-5                  [1, 32, 31, 31]           --\n","│    │    └─Sequential: 3-7                   [1, 32, 31, 31]           (10,000)\n","│    └─InvertedResidual: 2-6                  [1, 32, 31, 31]           --\n","│    │    └─Sequential: 3-8                   [1, 32, 31, 31]           (14,848)\n","│    └─InvertedResidual: 2-7                  [1, 32, 31, 31]           --\n","│    │    └─Sequential: 3-9                   [1, 32, 31, 31]           (14,848)\n","│    └─InvertedResidual: 2-8                  [1, 64, 16, 16]           --\n","│    │    └─Sequential: 3-10                  [1, 64, 16, 16]           (21,056)\n","│    └─InvertedResidual: 2-9                  [1, 64, 16, 16]           --\n","│    │    └─Sequential: 3-11                  [1, 64, 16, 16]           (54,272)\n","│    └─InvertedResidual: 2-10                 [1, 64, 16, 16]           --\n","│    │    └─Sequential: 3-12                  [1, 64, 16, 16]           (54,272)\n","│    └─InvertedResidual: 2-11                 [1, 64, 16, 16]           --\n","│    │    └─Sequential: 3-13                  [1, 64, 16, 16]           (54,272)\n","│    └─InvertedResidual: 2-12                 [1, 96, 16, 16]           --\n","│    │    └─Sequential: 3-14                  [1, 96, 16, 16]           (66,624)\n","│    └─InvertedResidual: 2-13                 [1, 96, 16, 16]           --\n","│    │    └─Sequential: 3-15                  [1, 96, 16, 16]           (118,272)\n","│    └─InvertedResidual: 2-14                 [1, 96, 16, 16]           --\n","│    │    └─Sequential: 3-16                  [1, 96, 16, 16]           (118,272)\n","│    └─InvertedResidual: 2-15                 [1, 160, 8, 8]            --\n","│    │    └─Sequential: 3-17                  [1, 160, 8, 8]            (155,264)\n","│    └─InvertedResidual: 2-16                 [1, 160, 8, 8]            --\n","│    │    └─Sequential: 3-18                  [1, 160, 8, 8]            (320,000)\n","│    └─InvertedResidual: 2-17                 [1, 160, 8, 8]            --\n","│    │    └─Sequential: 3-19                  [1, 160, 8, 8]            (320,000)\n","│    └─InvertedResidual: 2-18                 [1, 320, 8, 8]            --\n","│    │    └─Sequential: 3-20                  [1, 320, 8, 8]            (473,920)\n","│    └─ConvBNActivation: 2-19                 [1, 1280, 8, 8]           --\n","│    │    └─Conv2d: 3-21                      [1, 1280, 8, 8]           (409,600)\n","│    │    └─BatchNorm2d: 3-22                 [1, 1280, 8, 8]           (2,560)\n","│    │    └─ReLU6: 3-23                       [1, 1280, 8, 8]           --\n","├─Linear: 1-2                                 [1, 2]                    2,562\n","===============================================================================================\n","Total params: 2,226,434\n","Trainable params: 2,562\n","Non-trainable params: 2,223,872\n","Total mult-adds (M): 378.33\n","===============================================================================================\n","Input size (MB): 0.71\n","Forward/backward pass size (MB): 130.67\n","Params size (MB): 8.91\n","Estimated Total Size (MB): 140.29\n","==============================================================================================="]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kQyN2HuS3LGM","outputId":"5e6b5bfb-6c62-4a3d-c986-bab91b80f9c1"},"source":["train_long(model,train_loader,test_loader,loss_fn=torch.nn.CrossEntropyLoss(),epochs=1,print_freq=90)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, minibatch 0: train acc = 0.5625, train loss = 0.021763350814580917\n","Epoch 0, minibatch 90: train acc = 0.53125, train loss = 0.03625593080625429\n","Epoch 0, minibatch 180: train acc = 0.5495511049723757, train loss = 0.030138384571391574\n","Epoch 0, minibatch 270: train acc = 0.558809963099631, train loss = 0.02753588722200851\n","Epoch 0, minibatch 360: train acc = 0.5642313019390581, train loss = 0.026217878029947465\n","Epoch 0, minibatch 450: train acc = 0.5649944567627494, train loss = 0.02567697681503127\n","Epoch 0, minibatch 540: train acc = 0.5666589648798521, train loss = 0.025342914842193094\n"]}]},{"cell_type":"code","metadata":{"id":"47n96gBx3Nm6"},"source":[""],"execution_count":null,"outputs":[]}]}